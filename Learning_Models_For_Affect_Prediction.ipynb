{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import random\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import gpflow\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generalDat = pd.read_csv('hmm/finalMoodData.csv')\n",
    "group1data = pd.read_csv('hmm/group1data.csv')\n",
    "group2data = pd.read_csv('hmm/group2data.csv')\n",
    "group3data = pd.read_csv('hmm/group3data.csv')\n",
    "dataprofile = pd.read_csv('hmm/GMProfileDt.csv')\n",
    "sias =  pd.read_csv('hmm/SIAS.csv')\n",
    "groupings = pd.read_csv('hmm/GMeanMoodDt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(col):\n",
    "    \"\"\"\n",
    "    col: is a 1D array or list\n",
    "    purpose: Takes in a column of categorical data and returns an R*N array of a one hot encoding\n",
    "    with R categories\n",
    "    \"\"\"\n",
    "    values = array(col)\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    #print integer_encoded\n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    return onehot_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = groupings\n",
    "dataset = dataset.sort_values(['date_long'], ascending = True)\n",
    "y = dataset.pop('pid')\n",
    "X = dataset\n",
    "#Stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)\n",
    "#result1 = X_train.sort_values(['date_long'], ascending= True)\n",
    "X_train = X_train[predictors]\n",
    "print X_train.shape\n",
    "\n",
    "#result2 = X_test.sort_values(['date_long'], ascending= True)\n",
    "X_test = X_test[predictors]\n",
    "dat = X_train.append(X_test)\n",
    "dataset = dat[predictors]\n",
    "\n",
    "#print dataset.shape\n",
    "np.random.seed(0)\n",
    "\n",
    "# load dataset\n",
    "#dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "\n",
    "encoded = one_hot_encoding(values[:,1])\n",
    "values = np.delete(values, 1, 1)\n",
    "values = np.concatenate((values, encoded), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "encoded = one_hot_encoding(values[:,1].astype(str))\n",
    "values = np.delete(values, 1, 1)\n",
    "values = np.concatenate((values, encoded), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "#print scaled.shape\n",
    "# frame as supervised learning\n",
    "#reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed = scaled\n",
    "#print reframed\n",
    "#print(reframed.shape)\n",
    "\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed\n",
    "n_train_hours = X_train.shape[0]\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, 1:], train[:, 0]\n",
    "test_X, test_y = test[:, 1:], test[:, 0]\n",
    "\n",
    "\n",
    "train_y = train_y.reshape((train_y.shape[0], 1))\n",
    "test_y = test_y.reshape((test_y.shape[0], 1))\n",
    "print train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regression with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dim = train_X.shape[1]\n",
    "k = gpflow.kernels.RBF(dim, lengthscales= 20)\n",
    "m = gpflow.gpr.GPR(X = train_X, Y = train_y ,kern = k )\n",
    "m.optimize(maxiter=30)\n",
    "predic = m.predict_f(test_X)\n",
    "# make a prediction\n",
    "pred = predic[0]\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((pred, test_X), axis=1)\n",
    "#print inv_yhat.shape\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print 'Test RMSE: %.3f' % rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SVM with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVR(C=1.0, epsilon=0.1)\n",
    "clf.fit(train_X, train_y) \n",
    "# make a prediction\n",
    "predic = clf.predict(test_X)\n",
    "pred = predic.reshape((test_X.shape[0], 1))\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((pred, test_X), axis=1)\n",
    "#print inv_yhat.shape\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print 'Test RMSE: %.3f' % rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(train_X, train_y)\n",
    "# make a prediction\n",
    "predic = clf.predict(test_X)\n",
    "pred = predic.reshape((test_X.shape[0], 1))\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((pred, test_X), axis=1)\n",
    "#print inv_yhat.shape\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print 'Test RMSE: %.3f' % rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "clf.fit(train_X, train_y)\n",
    "# make a prediction\n",
    "predic = clf.predict(test_X)\n",
    "pred = predic.reshape((test_X.shape[0], 1))\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((pred, test_X), axis=1)\n",
    "#print inv_yhat.shape\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print 'Test RMSE: %.3f' % rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following are models based on subgroups of participant cohort "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> Group-based with Gaussian Processes</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = []\n",
    "for j in grp:\n",
    "    for i in groupings[j].unique():\n",
    "        data = groupings[groupings[j] == i]\n",
    "        data = data.sort_values(['date_long'], ascending = True)\n",
    "        y = data.pop('pid')\n",
    "        X = data\n",
    "        X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)\n",
    "        #result1 = X_train.sort_values(['date_long'], ascending= True)\n",
    "        X_train = X_train[predictors]\n",
    "        #print X_train.shape\n",
    "\n",
    "        #result2 = X_test.sort_values(['date_long'], ascending= True)\n",
    "        X_test = X_test[predictors]\n",
    "        #print X_test.head()\n",
    "        dat = X_train.append(X_test)\n",
    "        data = dat[predictors]\n",
    "        #print data.shape\n",
    "        np.random.seed(0)\n",
    "        # load dataset\n",
    "        #dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "        values = data.values\n",
    "        # integer encode direction\n",
    "        #encoder = LabelEncoder()\n",
    "        #values[:,4] = encoder.fit_transform(values[:,4])\n",
    "        encoded = one_hot_encoding(values[:,1])\n",
    "        values = np.delete(values, 1, 1)\n",
    "        values = np.concatenate((values, encoded), axis=1)\n",
    "\n",
    "        encoded = one_hot_encoding(values[:,1].astype(str))\n",
    "        values = np.delete(values, 1, 1)\n",
    "        values = np.concatenate((values, encoded), axis=1)\n",
    "\n",
    "\n",
    "        # ensure all data is float\n",
    "        values = values.astype('float32')\n",
    "        # normalize features\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled = scaler.fit_transform(values)\n",
    "        #print scaled.shape\n",
    "\n",
    "        # drop columns we don't want to predict\n",
    "        reframed = scaled\n",
    "\n",
    "\n",
    "        # split into train and test sets\n",
    "        values = reframed\n",
    "        n_train_hours = X_train.shape[0]\n",
    "        train = values[:n_train_hours, :]\n",
    "        test = values[n_train_hours:, :]\n",
    "        # split into input and outputs\n",
    "        train_X, train_y = train[:, 1:], train[:, 0]\n",
    "        test_X, test_y = test[:, 1:], test[:, 0]\n",
    "        # reshape input to be 3D [samples, timesteps, features]\n",
    "        train_y = train_y.reshape((train_y.shape[0], 1))\n",
    "        test_y = test_y.reshape((test_y.shape[0], 1))\n",
    "        print train_X.shape, train_y.shape, test_X.shape, test_y.shape\n",
    "\n",
    "        dim = train_X.shape[1]\n",
    "        k = gpflow.kernels.RBF(dim, lengthscales= 20)\n",
    "        m = gpflow.gpr.GPR(X = train_X, Y = train_y ,kern = k ) \n",
    "        m.optimize(maxiter=30)\n",
    "        predic = m.predict_f(test_X)\n",
    "        pred = predic[0]\n",
    "        # make a prediction\n",
    "        #yhat = model.predict(test_X)\n",
    "        #test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        # invert scaling for forecast\n",
    "        inv_yhat = concatenate((pred, test_X), axis=1)\n",
    "        #print inv_yhat.shape\n",
    "        inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "        inv_yhat = inv_yhat[:,0]\n",
    "        # invert scaling for actual\n",
    "        test_y = test_y.reshape((len(test_y), 1))\n",
    "        inv_y = concatenate((test_y, test_X), axis=1)\n",
    "        inv_y = scaler.inverse_transform(inv_y)\n",
    "        inv_y = inv_y[:,0]\n",
    "        # calculate RMSE\n",
    "        rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "        print 'Test RMSE: %.3f' % rmse\n",
    "        table.append({'class': j ,'group': i, 'RMSE':  rmse,  '#pid': len(y.unique()), 'dim':  data.shape, 'size': data.shape[0], \n",
    "                     'Y': inv_y, 'Pred':inv_yhat })\n",
    "\n",
    "results = pd.DataFrame(table) \n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting summary results from subgroup performance\n",
    "\n",
    "tal = []\n",
    "for i in jung['class'].unique():\n",
    "    h = jung[jung['class'] == i]\n",
    "    h['wRMSE'] = (h['RMSE'] * h['size'])/ np.sum(h['size']) \n",
    "    #print h.head(n =10)\n",
    "    tal.append({'class': i ,'WRMSE': np.sum(h['wRMSE']), 'SD': np.std(h['RMSE']) })\n",
    "\n",
    "\n",
    "tally = pd.DataFrame(tal) \n",
    "print tally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
